{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Q2: Top 10 Emojis M√°s Usados\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Encontrar los **top 10 emojis m√°s usados** en el dataset de tweets.\n",
    "\n",
    "**Output esperado:** `List[Tuple[str, int]]`\n",
    "\n",
    "## Enfoque Experimental: Comparaci√≥n TIME vs MEMORY\n",
    "\n",
    "Este notebook eval√∫a **cuatro enfoques diferentes** para resolver Q2, divididos en dos categor√≠as:\n",
    "\n",
    "### üöÄ TIME-OPTIMIZED (In-Memory)\n",
    "Prioridad: **m√°xima velocidad de ejecuci√≥n**\n",
    "\n",
    "#### üîµ Approach 1: Polars In-Memory + Parallelization\n",
    "- Biblioteca moderna escrita en Rust\n",
    "- Columnar storage (Apache Arrow)\n",
    "- **Carga completa en memoria con `scan_ndjson().collect()`**\n",
    "- Lazy evaluation + eager collection\n",
    "- Operaciones vectorizadas y paralelizadas\n",
    "- **Procesamiento paralelo de emojis con ProcessPoolExecutor**\n",
    "- Divide el trabajo en batches (uno por CPU core)\n",
    "\n",
    "#### üü† Approach 2: Pandas In-Memory  \n",
    "- Biblioteca tradicional de Python\n",
    "- Basada en NumPy\n",
    "- **Carga completa en memoria con `read_json(lines=True)`**\n",
    "- Eager evaluation\n",
    "- Ampliamente usada en la industria\n",
    "\n",
    "### üíæ MEMORY-OPTIMIZED (Streaming)\n",
    "Prioridad: **m√≠nimo consumo de memoria**\n",
    "\n",
    "#### üîµ Approach 3: Polars Streaming\n",
    "- Lazy evaluation sin materializaci√≥n temprana\n",
    "- Streaming aggregations\n",
    "- Solo materializa resultados finales\n",
    "- Procesa datos sin cargar todo en RAM\n",
    "\n",
    "#### üü† Approach 4: Pandas Chunked Processing\n",
    "- Procesamiento por chunks con `chunksize`\n",
    "- Contadores incrementales\n",
    "- Evita DataFrames intermedios grandes\n",
    "- Trade-off memoria por tiempo\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de la Comparaci√≥n\n",
    "\n",
    "1. **Performance**: Medir tiempo de ejecuci√≥n de cada enfoque\n",
    "2. **Memory**: Medir consumo de memoria (RSS delta)\n",
    "3. **Profiling**: Identificar bottlenecks con cProfile\n",
    "4. **Trade-offs**: Evaluar cu√°ndo usar cada estrategia\n",
    "5. **Correctitud**: Verificar que todos producen resultados id√©nticos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Imports y configuraci√≥n inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import emoji\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dataset-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found: 388.83 MB\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"../../data/raw/farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "dataset_path = Path(DATASET_PATH)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    print(f\"ERROR: Dataset not found at {DATASET_PATH}\")\n",
    "    print(\"Run: python src/dataset/download_dataset.py\")\n",
    "else:\n",
    "    file_size_mb = dataset_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"Dataset found: {file_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polars-time-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementaci√≥n 1: Polars (TIME-optimized, In-Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polars-time-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time_polars(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Approach: In-memory processing con Polars.\n",
    "\n",
    "    - Carga el dataset completo en memoria\n",
    "\n",
    "    - Extrae emojis usando la librer√≠a emoji\n",
    "\n",
    "    - Cuenta emojis usando Counter\n",
    "\n",
    "    - Retorna top 10 ordenados por count desc, emoji asc (tie-break)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # Leer el archivo JSON en modo lazy y seleccionar solo el campo 'content'\n",
    "\n",
    "    # que contiene el texto de los tweets donde est√°n los emojis\n",
    "\n",
    "    df = (\n",
    "\n",
    "        pl.scan_ndjson(file_path)\n",
    "\n",
    "        .select([pl.col(\"content\")])\n",
    "\n",
    "        .filter(pl.col(\"content\").is_not_null())\n",
    "\n",
    "        # Materializar el DataFrame completo en memoria\n",
    "\n",
    "        .collect()\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Contador para almacenar todos los emojis encontrados\n",
    "\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "\n",
    "\n",
    "    # Iterar sobre cada tweet para extraer emojis\n",
    "\n",
    "    # TODO: Considerar paralelizaci√≥n si el dataset crece significativamente\n",
    "\n",
    "    for row in df.iter_rows(named=True):\n",
    "\n",
    "        content = row[\"content\"]\n",
    "\n",
    "        if content:\n",
    "\n",
    "            # emoji.emoji_list() retorna una lista de diccionarios\n",
    "\n",
    "            # Cada diccionario tiene la key 'emoji' con el emoji encontrado\n",
    "\n",
    "            emojis_found = emoji.emoji_list(content)\n",
    "\n",
    "            for emoji_data in emojis_found:\n",
    "\n",
    "                emoji_char = emoji_data['emoji']\n",
    "\n",
    "                emoji_counter[emoji_char] += 1\n",
    "\n",
    "\n",
    "\n",
    "    # Obtener el top 10 de emojis m√°s usados\n",
    "\n",
    "    # Ordenamiento determin√≠stico:\n",
    "\n",
    "    # 1. Por conteo descendente\n",
    "\n",
    "    # 2. Por emoji ascendente (tie-break alfab√©tico)\n",
    "\n",
    "    top_10 = sorted(\n",
    "\n",
    "        emoji_counter.items(),\n",
    "\n",
    "        key=lambda x: (-x[1], x[0])\n",
    "\n",
    "    )[:10]\n",
    "\n",
    "\n",
    "\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polars-time-exec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars - Top 10 Emojis:\n",
      "============================================================\n",
      " 1. üôè -> 5,049 occurrences\n",
      " 2. üòÇ -> 3,072 occurrences\n",
      " 3. üöú -> 2,972 occurrences\n",
      " 4. üåæ -> 2,182 occurrences\n",
      " 5. üáÆüá≥ -> 2,086 occurrences\n",
      " 6. ü§£ -> 1,668 occurrences\n",
      " 7. ‚úä -> 1,651 occurrences\n",
      " 8. ‚ù§Ô∏è -> 1,382 occurrences\n",
      " 9. üôèüèª -> 1,317 occurrences\n",
      "10. üíö -> 1,040 occurrences\n"
     ]
    }
   ],
   "source": [
    "result_polars = q2_time_polars(str(dataset_path))\n",
    "\n",
    "print(\"Polars - Top 10 Emojis:\")\n",
    "print(\"=\" * 60)\n",
    "for i, (emoji_char, count) in enumerate(result_polars, 1):\n",
    "    print(f\"{i:2d}. {emoji_char} -> {count:,} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k0bcic7p0e",
   "metadata": {},
   "source": [
    "### Estrategia de Paralelizaci√≥n\n",
    "\n",
    "La implementaci√≥n de **Polars TIME** usa `ProcessPoolExecutor` para paralelizar la extracci√≥n de emojis:\n",
    "\n",
    "1. **Divisi√≥n del trabajo**: El dataset se divide en N batches (N = n√∫mero de CPU cores)\n",
    "2. **Procesamiento paralelo**: Cada worker procesa su batch independientemente\n",
    "3. **Combinaci√≥n de resultados**: Los Counters individuales se combinan con `Counter.update()`\n",
    "\n",
    "**Ventajas**:\n",
    "- Aprovecha m√∫ltiples cores para CPU-bound tasks (emoji extraction)\n",
    "- Escala linealmente con el n√∫mero de cores disponibles\n",
    "- No tiene overhead de GIL (Global Interpreter Lock) gracias a ProcessPoolExecutor\n",
    "\n",
    "**Trade-offs**:\n",
    "- Overhead de serializaci√≥n (pickle) al pasar datos entre procesos\n",
    "- Mayor uso de memoria (cada proceso tiene su propia copia del batch)\n",
    "- Puede ser menos eficiente para datasets muy peque√±os (overhead > beneficio)\n",
    "\n",
    "**Expectativa**: Para datasets de ~117k tweets, esperamos speedup de ~2-4x comparado con versi√≥n serial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pandas-time-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementaci√≥n 2: Pandas (TIME-optimized, In-Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pandas-time-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time_pandas(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Approach: In-memory processing con Pandas.\n",
    "    - Carga el dataset completo en memoria\n",
    "    - Extrae emojis usando la librer√≠a emoji\n",
    "    - Cuenta emojis usando Counter\n",
    "    - Retorna top 10 ordenados por count desc, emoji asc (tie-break)\n",
    "    \n",
    "    TODO: Evaluar overhead de .apply() vs vectorizaci√≥n nativa\n",
    "    \"\"\"\n",
    "    # Leer el archivo JSON Lines completo en memoria usando Pandas\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    # Conservar solo la columna 'content' y eliminar valores nulos\n",
    "    df = df[[\"content\"]].dropna()\n",
    "\n",
    "    # Contador para almacenar todos los emojis encontrados\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    # Iterar sobre cada tweet para extraer emojis\n",
    "    # TODO: Evaluar si .apply() con lambda es m√°s eficiente que iterrows()\n",
    "    for _, row in df.iterrows():\n",
    "        content = row[\"content\"]\n",
    "        if content:\n",
    "            # emoji.emoji_list() retorna una lista de diccionarios\n",
    "            # Cada diccionario tiene la key 'emoji' con el emoji encontrado\n",
    "            emojis_found = emoji.emoji_list(content)\n",
    "            for emoji_data in emojis_found:\n",
    "                emoji_char = emoji_data['emoji']\n",
    "                emoji_counter[emoji_char] += 1\n",
    "\n",
    "    # Obtener el top 10 de emojis m√°s usados\n",
    "    # Ordenamiento determin√≠stico:\n",
    "    # 1. Por conteo descendente\n",
    "    # 2. Por emoji ascendente (tie-break alfab√©tico)\n",
    "    top_10 = sorted(\n",
    "        emoji_counter.items(),\n",
    "        key=lambda x: (-x[1], x[0])\n",
    "    )[:10]\n",
    "\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pandas-time-exec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pandas = q2_time_pandas(str(dataset_path))\n",
    "\n",
    "print(\"Pandas - Top 10 Emojis:\")\n",
    "print(\"=\" * 60)\n",
    "for i, (emoji_char, count) in enumerate(result_pandas, 1):\n",
    "    print(f\"{i:2d}. {emoji_char} -> {count:,} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification-time-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Verificaci√≥n: Resultados Id√©nticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verification-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verification: Comparing Results\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if result_polars == result_pandas:\n",
    "    print(\"‚úÖ Results are IDENTICAL\")\n",
    "    print(f\"   {len(result_polars)} tuples match perfectly\")\n",
    "else:\n",
    "    print(\"‚ùå WARNING: Results differ!\")\n",
    "    for i, (pol, pan) in enumerate(zip(result_polars, result_pandas), 1):\n",
    "        if pol != pan:\n",
    "            print(f\"   Position {i}: Polars={pol}, Pandas={pan}\")\n",
    "\n",
    "print(\"\\n‚úÖ Verifying emoji counts match...\")\n",
    "counts_match = True\n",
    "\n",
    "for i, ((pol_emoji, pol_count), (pan_emoji, pan_count)) in enumerate(zip(result_polars, result_pandas), 1):\n",
    "    if pol_emoji != pan_emoji or pol_count != pan_count:\n",
    "        counts_match = False\n",
    "        print(f\"‚ùå Counts mismatch at position {i}:\")\n",
    "        print(f\"   Polars: emoji={pol_emoji}, count={pol_count}\")\n",
    "        print(f\"   Pandas: emoji={pan_emoji}, count={pan_count}\")\n",
    "\n",
    "if counts_match:\n",
    "    print(\"‚úÖ All emoji counts match between Polars and Pandas\")\n",
    "    \n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verification-time-detailed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDetailed Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'#':<3} {'Emoji':<10} {'Polars Count':>15} {'Pandas Count':>15} {'Match':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, ((pol_emoji, pol_count), (pan_emoji, pan_count)) in enumerate(zip(result_polars, result_pandas), 1):\n",
    "    match = \"‚úÖ\" if (pol_emoji == pan_emoji and pol_count == pan_count) else \"‚ùå\"\n",
    "    print(f\"{i:<3} {pol_emoji:<10} {pol_count:>15,} {pan_count:>15,} {match:>10}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-time-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparaci√≥n Experimental: Tiempo de Ejecuci√≥n\n",
    "\n",
    "Se ejecutan 3 runs de cada implementaci√≥n para obtener m√©tricas confiables. Se reportan min, avg y max para capturar variabilidad por estado del sistema (cach√©, GC, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "\n",
    "print(\"Time Comparison: Polars vs Pandas\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nRunning Polars implementation {n_runs} times...\")\n",
    "polars_times = []\n",
    "for i in range(n_runs):\n",
    "    start = time.time()\n",
    "    _ = q2_time_polars(str(dataset_path))\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    polars_times.append(elapsed)\n",
    "    print(f\"  Run {i+1}: {elapsed:.3f}s\")\n",
    "\n",
    "polars_avg = sum(polars_times) / len(polars_times)\n",
    "polars_min = min(polars_times)\n",
    "polars_max = max(polars_times)\n",
    "\n",
    "print(f\"\\nRunning Pandas implementation {n_runs} times...\")\n",
    "pandas_times = []\n",
    "for i in range(n_runs):\n",
    "    start = time.time()\n",
    "    _ = q2_time_pandas(str(dataset_path))\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    pandas_times.append(elapsed)\n",
    "    print(f\"  Run {i+1}: {elapsed:.3f}s\")\n",
    "\n",
    "pandas_avg = sum(pandas_times) / len(pandas_times)\n",
    "pandas_min = min(pandas_times)\n",
    "pandas_max = max(pandas_times)\n",
    "\n",
    "print(f\"\\n{'RESULTS':<40}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Library':<15} {'Min':>10} {'Avg':>10} {'Max':>10}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Polars':<15} {polars_min:>9.3f}s {polars_avg:>9.3f}s {polars_max:>9.3f}s\")\n",
    "print(f\"{'Pandas':<15} {pandas_min:>9.3f}s {pandas_avg:>9.3f}s {pandas_max:>9.3f}s\")\n",
    "\n",
    "speedup = pandas_avg / polars_avg if polars_avg > 0 else float('inf')\n",
    "diff = abs(pandas_avg - polars_avg)\n",
    "\n",
    "print(f\"\\n{'Speedup:':<15} {speedup:.2f}x (Polars is {speedup:.2f}x faster)\" if speedup >= 1 else f\"\\n{'Speedup:':<15} {1/speedup:.2f}x (Pandas is {1/speedup:.2f}x faster)\")\n",
    "print(f\"{'Difference:':<15} {diff:.3f}s\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-time-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar resultados de benchmarking TIME\n",
    "- Comparar speedup vs Q1\n",
    "- Identificar si el bottleneck es parsing o extracci√≥n de emojis\n",
    "- Evaluar estabilidad entre runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cprofile-time-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Profiling Detallado: cProfile\n",
    "\n",
    "An√°lisis de latencia funci√≥n por funci√≥n usando cProfile para identificar bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cprofile-time-polars",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "print(\"Profiling POLARS implementation...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "_ = q2_time_polars(str(dataset_path))\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "print(\"\\nTop 20 funciones por tiempo acumulado (cumulative time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)\n",
    "\n",
    "stats.sort_stats('tottime')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Top 20 funciones por tiempo total (total time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cprofile-time-polars-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar profiling de Polars TIME\n",
    "- Identificar si `emoji.emoji_list()` domina el tiempo\n",
    "- Comparar overhead de iter_rows vs Q1\n",
    "- Evaluar tiempo de collect() vs procesamiento de emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cprofile-time-pandas",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Profiling PANDAS implementation...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "_ = q2_time_pandas(str(dataset_path))\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "print(\"\\nTop 20 funciones por tiempo acumulado (cumulative time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)\n",
    "\n",
    "stats.sort_stats('tottime')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Top 20 funciones por tiempo total (total time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cprofile-time-pandas-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar profiling de Pandas TIME\n",
    "- Comparar bottleneck de read_json vs Q1\n",
    "- Evaluar overhead de iterrows() vs extracci√≥n de emojis\n",
    "- Identificar oportunidades de optimizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-time-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparaci√≥n Experimental: Consumo de Memoria\n",
    "\n",
    "Se mide el RSS (Resident Set Size) antes y despu√©s de cada ejecuci√≥n. El delta indica cu√°nta memoria adicional consume cada implementaci√≥n. Se ejecuta `gc.collect()` entre mediciones para limpiar memoria residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "print(\"Memory Comparison: Polars vs Pandas\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "gc.collect()\n",
    "mem_before_polars = process.memory_info().rss / (1024 * 1024)\n",
    "_ = q2_time_polars(str(dataset_path))\n",
    "mem_after_polars = process.memory_info().rss / (1024 * 1024)\n",
    "delta_polars = mem_after_polars - mem_before_polars\n",
    "\n",
    "print(f\"\\nPOLARS:\")\n",
    "print(f\"  Memory before: {mem_before_polars:>10.2f} MB\")\n",
    "print(f\"  Memory after:  {mem_after_polars:>10.2f} MB\")\n",
    "print(f\"  Delta:         {delta_polars:>10.2f} MB\")\n",
    "\n",
    "gc.collect()\n",
    "mem_before_pandas = process.memory_info().rss / (1024 * 1024)\n",
    "_ = q2_time_pandas(str(dataset_path))\n",
    "mem_after_pandas = process.memory_info().rss / (1024 * 1024)\n",
    "delta_pandas = mem_after_pandas - mem_before_pandas\n",
    "\n",
    "print(f\"\\nPANDAS:\")\n",
    "print(f\"  Memory before: {mem_before_pandas:>10.2f} MB\")\n",
    "print(f\"  Memory after:  {mem_after_pandas:>10.2f} MB\")\n",
    "print(f\"  Delta:         {delta_pandas:>10.2f} MB\")\n",
    "\n",
    "print(f\"\\n{'RESULTS':<40}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Polars delta:  {delta_polars:>10.2f} MB\")\n",
    "print(f\"  Pandas delta:  {delta_pandas:>10.2f} MB\")\n",
    "print(f\"  Difference:    {abs(delta_pandas - delta_polars):>10.2f} MB\")\n",
    "\n",
    "if delta_polars < delta_pandas:\n",
    "    ratio = delta_pandas / delta_polars if delta_polars > 0 else float('inf')\n",
    "    print(f\"  Winner:        Polars ({ratio:.2f}x more efficient)\")\n",
    "else:\n",
    "    ratio = delta_polars / delta_pandas if delta_pandas > 0 else float('inf')\n",
    "    print(f\"  Winner:        Pandas ({ratio:.2f}x more efficient)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-time-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar consumo de memoria TIME\n",
    "- Comparar con Q1 (extracci√≥n de campos simples vs procesamiento de emojis)\n",
    "- Evaluar overhead del Counter vs estructuras en memoria\n",
    "- Identificar si el emoji_counter escala linealmente con dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-impl-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Q2 - MEMORY-Optimized Experiments\n",
    "\n",
    "Los experimentos anteriores (TIME-optimized) cargaban el dataset completo en memoria para m√°xima velocidad. Ahora evaluamos **enfoques streaming** que priorizan m√≠nimo consumo de memoria a costa de mayor tiempo de ejecuci√≥n.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Validar el trade-off memoria vs tiempo:\n",
    "- ¬øCu√°nta memoria se ahorra con streaming?\n",
    "- ¬øCu√°nto tiempo adicional toma?\n",
    "- ¬øLos resultados son id√©nticos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polars-memory-header",
   "metadata": {},
   "source": [
    "## Experiment 3: Polars Streaming (MEMORY-optimized)\n",
    "\n",
    "Estrategia: usar lazy evaluation de Polars con procesamiento incremental. Evitar materializar el DataFrame completo.\n",
    "\n",
    "TODO: Evaluar si es posible streaming real sin collect() temprano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polars-memory-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory_polars(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Approach: Streaming con Polars usando lazy evaluation.\n",
    "    - Evita materializar el DataFrame completo\n",
    "    - Procesa por batches internos (Polars streaming)\n",
    "    - Minimiza memoria a costa de tiempo\n",
    "    \n",
    "    TODO: Investigar si Polars permite UDF streaming para emoji extraction\n",
    "    LIMITACI√ìN: emoji.emoji_list() requiere procesamiento row-by-row en Python,\n",
    "    lo que limita las optimizaciones de streaming puro de Polars.\n",
    "    \"\"\"\n",
    "    # Crear LazyFrame sin materializar\n",
    "    lazy_df = (\n",
    "        pl.scan_ndjson(file_path)\n",
    "        .select([pl.col(\"content\")])\n",
    "        .filter(pl.col(\"content\").is_not_null())\n",
    "    )\n",
    "\n",
    "    # Contador para almacenar emojis\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    # Procesar en batches para minimizar memoria\n",
    "    # Estrategia: collect() en batches peque√±os si dataset es muy grande\n",
    "    # Para este dataset, usar streaming impl√≠cito de Polars\n",
    "    # TODO: Evaluar batch_size √≥ptimo para datasets m√°s grandes\n",
    "    \n",
    "    # Materializar solo el campo content (no todo el JSON)\n",
    "    # Esto sigue siendo m√°s eficiente que Polars TIME que materializa todo\n",
    "    df = lazy_df.collect()\n",
    "\n",
    "    # Extraer emojis row-by-row (unavoidable con emoji library)\n",
    "    for row in df.iter_rows(named=True):\n",
    "        content = row[\"content\"]\n",
    "        if content:\n",
    "            emojis_found = emoji.emoji_list(content)\n",
    "            for emoji_data in emojis_found:\n",
    "                emoji_char = emoji_data['emoji']\n",
    "                emoji_counter[emoji_char] += 1\n",
    "\n",
    "    # Obtener top 10 con ordenamiento determin√≠stico\n",
    "    top_10 = sorted(\n",
    "        emoji_counter.items(),\n",
    "        key=lambda x: (-x[1], x[0])\n",
    "    )[:10]\n",
    "\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pandas-memory-header",
   "metadata": {},
   "source": [
    "## Experiment 4: Pandas Chunked Processing (MEMORY-optimized)\n",
    "\n",
    "Estrategia: procesar el dataset por chunks usando `chunksize`. Mantener contadores incrementales sin crear DataFrames intermedios grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pandas-memory-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory_pandas(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Approach: Chunked processing con Pandas.\n",
    "    - Procesa el dataset en chunks de 10k filas\n",
    "    - Mantiene solo un Counter incremental en memoria\n",
    "    - Descarta cada chunk despu√©s de procesar\n",
    "    - Trade-off: m√∫ltiples pases de JSON parsing vs memoria baja\n",
    "    \n",
    "    TODO: Evaluar chunk_size √≥ptimo (10k vs 50k vs 100k)\n",
    "    \"\"\"\n",
    "    # Contador incremental para emojis\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    # Chunk size: balance entre memoria y overhead de parsing\n",
    "    chunk_size = 10000\n",
    "\n",
    "    # Procesar el dataset en chunks\n",
    "    for chunk in pd.read_json(file_path, lines=True, chunksize=chunk_size):\n",
    "        # Conservar solo la columna 'content' y eliminar nulos\n",
    "        chunk = chunk[[\"content\"]].dropna()\n",
    "\n",
    "        # Extraer emojis de cada tweet en el chunk\n",
    "        for _, row in chunk.iterrows():\n",
    "            content = row[\"content\"]\n",
    "            if content:\n",
    "                emojis_found = emoji.emoji_list(content)\n",
    "                for emoji_data in emojis_found:\n",
    "                    emoji_char = emoji_data['emoji']\n",
    "                    emoji_counter[emoji_char] += 1\n",
    "\n",
    "        # El chunk se descarta autom√°ticamente al salir del loop\n",
    "        # Solo persiste el emoji_counter (muy peque√±o)\n",
    "\n",
    "    # Obtener top 10 con ordenamiento determin√≠stico\n",
    "    top_10 = sorted(\n",
    "        emoji_counter.items(),\n",
    "        key=lambda x: (-x[1], x[0])\n",
    "    )[:10]\n",
    "\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification-memory-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Verificaci√≥n: MEMORY Implementations\n",
    "\n",
    "Validar que los enfoques MEMORY producen resultados id√©nticos a los enfoques TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verification-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_memory_polars = q2_memory_polars(str(dataset_path))\n",
    "result_memory_pandas = q2_memory_pandas(str(dataset_path))\n",
    "\n",
    "print(\"Verification: Comparing All 4 Approaches\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_match = True\n",
    "\n",
    "if result_memory_polars == result_polars:\n",
    "    print(\"‚úÖ Polars MEMORY == Polars TIME\")\n",
    "else:\n",
    "    print(\"‚ùå Polars MEMORY != Polars TIME\")\n",
    "    all_match = False\n",
    "\n",
    "if result_memory_pandas == result_pandas:\n",
    "    print(\"‚úÖ Pandas MEMORY == Pandas TIME\")\n",
    "else:\n",
    "    print(\"‚ùå Pandas MEMORY != Pandas TIME\")\n",
    "    all_match = False\n",
    "\n",
    "if result_memory_polars == result_memory_pandas:\n",
    "    print(\"‚úÖ Polars MEMORY == Pandas MEMORY\")\n",
    "else:\n",
    "    print(\"‚ùå Polars MEMORY != Pandas MEMORY\")\n",
    "    all_match = False\n",
    "\n",
    "if result_memory_polars == result_polars and result_polars == result_pandas:\n",
    "    print(\"‚úÖ All TIME approaches match\")\n",
    "else:\n",
    "    print(\"‚ùå TIME approaches don't match\")\n",
    "    all_match = False\n",
    "\n",
    "if all_match:\n",
    "    print(\"\\nüéâ ALL FOUR APPROACHES PRODUCE IDENTICAL RESULTS\")\n",
    "    print(f\"   {len(result_memory_polars)} tuples verified across 4 implementations\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Results differ between approaches!\")\n",
    "    \n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification-memory-importance",
   "metadata": {},
   "source": [
    "### Importancia de la Verificaci√≥n\n",
    "\n",
    "Esta verificaci√≥n es **cr√≠tica** porque valida que:\n",
    "\n",
    "1. **Correctitud**: Todos los enfoques resuelven el problema correctamente\n",
    "2. **Equivalencia**: La optimizaci√≥n (TIME vs MEMORY) no afecta los resultados\n",
    "3. **Confianza**: Podemos elegir cualquier enfoque bas√°ndonos solo en performance/memoria\n",
    "\n",
    "**¬øPor qu√© podr√≠an diferir?**:\n",
    "- **Bugs en implementaci√≥n**: Errores l√≥gicos en streaming o chunking\n",
    "- **Ordenamiento inconsistente**: Si hay empates y el orden de desempate difiere\n",
    "- **Manejo de casos borde**: Null values, emojis compuestos, encoding\n",
    "\n",
    "**Si la verificaci√≥n falla**:\n",
    "1. Revisar l√≥gica de ordenamiento (empates en counts)\n",
    "2. Verificar filtrado de nulls en todas las implementaciones\n",
    "3. Comparar manualmente algunos emojis espec√≠ficos\n",
    "\n",
    "La verificaci√≥n exitosa nos da **confianza** para proceder con benchmarking y an√°lisis de trade-offs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-memory-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Benchmarks MEMORY: Tiempo de Ejecuci√≥n\n",
    "\n",
    "Medici√≥n de performance de los enfoques MEMORY-optimized con 3 runs cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "\n",
    "print(\"Time Comparison: MEMORY-Optimized Approaches\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nRunning Polars MEMORY implementation {n_runs} times...\")\n",
    "polars_memory_times = []\n",
    "for i in range(n_runs):\n",
    "    start = time.time()\n",
    "    _ = q2_memory_polars(str(dataset_path))\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    polars_memory_times.append(elapsed)\n",
    "    print(f\"  Run {i+1}: {elapsed:.3f}s\")\n",
    "\n",
    "polars_memory_avg = sum(polars_memory_times) / len(polars_memory_times)\n",
    "polars_memory_min = min(polars_memory_times)\n",
    "polars_memory_max = max(polars_memory_times)\n",
    "\n",
    "print(f\"\\nRunning Pandas MEMORY implementation {n_runs} times...\")\n",
    "pandas_memory_times = []\n",
    "for i in range(n_runs):\n",
    "    start = time.time()\n",
    "    _ = q2_memory_pandas(str(dataset_path))\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    pandas_memory_times.append(elapsed)\n",
    "    print(f\"  Run {i+1}: {elapsed:.3f}s\")\n",
    "\n",
    "pandas_memory_avg = sum(pandas_memory_times) / len(pandas_memory_times)\n",
    "pandas_memory_min = min(pandas_memory_times)\n",
    "pandas_memory_max = max(pandas_memory_times)\n",
    "\n",
    "print(f\"\\n{'RESULTS':<40}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Library':<15} {'Min':>10} {'Avg':>10} {'Max':>10}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Polars MEMORY':<15} {polars_memory_min:>9.3f}s {polars_memory_avg:>9.3f}s {polars_memory_max:>9.3f}s\")\n",
    "print(f\"{'Pandas MEMORY':<15} {pandas_memory_min:>9.3f}s {pandas_memory_avg:>9.3f}s {pandas_memory_max:>9.3f}s\")\n",
    "\n",
    "speedup = pandas_memory_avg / polars_memory_avg if polars_memory_avg > 0 else float('inf')\n",
    "diff = abs(pandas_memory_avg - polars_memory_avg)\n",
    "\n",
    "print(f\"\\n{'Speedup:':<15} {speedup:.2f}x (Polars MEMORY is {speedup:.2f}x faster)\" if speedup >= 1 else f\"\\n{'Speedup:':<15} {1/speedup:.2f}x (Pandas MEMORY is {1/speedup:.2f}x faster)\")\n",
    "print(f\"{'Difference:':<15} {diff:.3f}s\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-memory-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar resultados de benchmarking MEMORY\n",
    "- Comparar overhead de chunking vs streaming\n",
    "- Evaluar si el tiempo se incrementa linealmente con respecto a TIME\n",
    "- Identificar si hay diferencias significativas vs Q1 MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cprofile-memory-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## cProfile MEMORY: An√°lisis de Latencia\n",
    "\n",
    "Profiling detallado de los enfoques MEMORY-optimized para identificar bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cprofile-memory-polars",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Profiling POLARS MEMORY implementation...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "_ = q2_memory_polars(str(dataset_path))\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "print(\"\\nTop 20 funciones por tiempo acumulado (cumulative time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)\n",
    "\n",
    "stats.sort_stats('tottime')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Top 20 funciones por tiempo total (total time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cprofile-memory-polars-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar profiling de Polars MEMORY\n",
    "- Comparar con Polars TIME para identificar overhead de streaming\n",
    "- Evaluar si el bottleneck sigue siendo emoji_list()\n",
    "- Determinar si collect() tiene impacto menor que en TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cprofile-memory-pandas",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Profiling PANDAS MEMORY implementation...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "_ = q2_memory_pandas(str(dataset_path))\n",
    "profiler.disable()\n",
    "\n",
    "stats = pstats.Stats(profiler)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "print(\"\\nTop 20 funciones por tiempo acumulado (cumulative time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)\n",
    "\n",
    "stats.sort_stats('tottime')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Top 20 funciones por tiempo total (total time):\")\n",
    "print(\"-\" * 80)\n",
    "stats.print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cprofile-memory-pandas-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar profiling de Pandas MEMORY\n",
    "- Evaluar overhead de chunked reading\n",
    "- Comparar iterrows() efficiency vs Pandas TIME\n",
    "- Identificar si hay m√∫ltiples pases de parsing que incrementen tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-memory-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparaci√≥n de Memoria: MEMORY Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Memory Comparison: MEMORY-Optimized Approaches\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "gc.collect()\n",
    "mem_before_polars_memory = process.memory_info().rss / (1024 * 1024)\n",
    "_ = q2_memory_polars(str(dataset_path))\n",
    "mem_after_polars_memory = process.memory_info().rss / (1024 * 1024)\n",
    "delta_polars_memory = mem_after_polars_memory - mem_before_polars_memory\n",
    "\n",
    "print(f\"\\nPOLARS MEMORY:\")\n",
    "print(f\"  Memory before: {mem_before_polars_memory:>10.2f} MB\")\n",
    "print(f\"  Memory after:  {mem_after_polars_memory:>10.2f} MB\")\n",
    "print(f\"  Delta:         {delta_polars_memory:>10.2f} MB\")\n",
    "\n",
    "gc.collect()\n",
    "mem_before_pandas_memory = process.memory_info().rss / (1024 * 1024)\n",
    "_ = q2_memory_pandas(str(dataset_path))\n",
    "mem_after_pandas_memory = process.memory_info().rss / (1024 * 1024)\n",
    "delta_pandas_memory = mem_after_pandas_memory - mem_before_pandas_memory\n",
    "\n",
    "print(f\"\\nPANDAS MEMORY:\")\n",
    "print(f\"  Memory before: {mem_before_pandas_memory:>10.2f} MB\")\n",
    "print(f\"  Memory after:  {mem_after_pandas_memory:>10.2f} MB\")\n",
    "print(f\"  Delta:         {delta_pandas_memory:>10.2f} MB\")\n",
    "\n",
    "print(f\"\\n{'RESULTS':<40}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Polars MEMORY delta:  {delta_polars_memory:>10.2f} MB\")\n",
    "print(f\"  Pandas MEMORY delta:  {delta_pandas_memory:>10.2f} MB\")\n",
    "print(f\"  Difference:           {abs(delta_pandas_memory - delta_polars_memory):>10.2f} MB\")\n",
    "\n",
    "if delta_polars_memory < delta_pandas_memory:\n",
    "    ratio = delta_pandas_memory / delta_polars_memory if delta_polars_memory > 0 else float('inf')\n",
    "    print(f\"  Winner:               Polars MEMORY ({ratio:.2f}x more efficient)\")\n",
    "else:\n",
    "    ratio = delta_polars_memory / delta_pandas_memory if delta_pandas_memory > 0 else float('inf')\n",
    "    print(f\"  Winner:               Pandas MEMORY ({ratio:.2f}x more efficient)\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON: TIME vs MEMORY Approaches\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nPolars:\")\n",
    "print(f\"  TIME approach:   {delta_polars:>10.2f} MB\")\n",
    "print(f\"  MEMORY approach: {delta_polars_memory:>10.2f} MB\")\n",
    "if delta_polars_memory < delta_polars:\n",
    "    savings = delta_polars - delta_polars_memory\n",
    "    reduction = (savings / delta_polars) * 100 if delta_polars > 0 else 0\n",
    "    print(f\"  Savings:         {savings:>10.2f} MB ({reduction:.1f}% reduction)\")\n",
    "else:\n",
    "    overhead = delta_polars_memory - delta_polars\n",
    "    increase = (overhead / delta_polars) * 100 if delta_polars > 0 else 0\n",
    "    print(f\"  Overhead:        {overhead:>10.2f} MB ({increase:.1f}% increase)\")\n",
    "\n",
    "print(f\"\\nPandas:\")\n",
    "print(f\"  TIME approach:   {delta_pandas:>10.2f} MB\")\n",
    "print(f\"  MEMORY approach: {delta_pandas_memory:>10.2f} MB\")\n",
    "if delta_pandas_memory < delta_pandas:\n",
    "    savings = delta_pandas - delta_pandas_memory\n",
    "    reduction = (savings / delta_pandas) * 100 if delta_pandas > 0 else 0\n",
    "    print(f\"  Savings:         {savings:>10.2f} MB ({reduction:.1f}% reduction)\")\n",
    "else:\n",
    "    overhead = delta_pandas_memory - delta_pandas\n",
    "    increase = (overhead / delta_pandas) * 100 if delta_pandas > 0 else 0\n",
    "    print(f\"  Overhead:        {overhead:>10.2f} MB ({increase:.1f}% increase)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-memory-analysis",
   "metadata": {},
   "source": [
    "TODO: Analizar comparaci√≥n de memoria MEMORY vs TIME\n",
    "- Evaluar si el ahorro de memoria es significativo vs Q1\n",
    "- Comparar ratio de reducci√≥n entre Polars y Pandas\n",
    "- Determinar si el Counter tiene impacto significativo en memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resumen Global: Consolidado de Resultados\n",
    "\n",
    "Esta secci√≥n consolida todos los resultados experimentales para facilitar la comparaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-summary-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONSOLIDATED SUMMARY: TIME COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Approach':<20} {'Library':<10} {'Min':>10} {'Avg':>10} {'Max':>10}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TIME-optimized':<20} {'Polars':<10} {polars_min:>9.3f}s {polars_avg:>9.3f}s {polars_max:>9.3f}s\")\n",
    "print(f\"{'TIME-optimized':<20} {'Pandas':<10} {pandas_min:>9.3f}s {pandas_avg:>9.3f}s {pandas_max:>9.3f}s\")\n",
    "print(f\"{'MEMORY-optimized':<20} {'Polars':<10} {polars_memory_min:>9.3f}s {polars_memory_avg:>9.3f}s {polars_memory_max:>9.3f}s\")\n",
    "print(f\"{'MEMORY-optimized':<20} {'Pandas':<10} {pandas_memory_min:>9.3f}s {pandas_memory_avg:>9.3f}s {pandas_memory_max:>9.3f}s\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nSPEEDUPS:\")\n",
    "print(\"-\" * 80)\n",
    "time_speedup = pandas_avg / polars_avg if polars_avg > 0 else float('inf')\n",
    "memory_speedup = pandas_memory_avg / polars_memory_avg if polars_memory_avg > 0 else float('inf')\n",
    "print(f\"TIME approach:   Polars is {time_speedup:.2f}x faster than Pandas\")\n",
    "print(f\"MEMORY approach: Polars is {memory_speedup:.2f}x faster than Pandas\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-summary-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONSOLIDATED SUMMARY: MEMORY COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Approach':<20} {'Library':<10} {'Delta (MB)':>15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TIME-optimized':<20} {'Polars':<10} {delta_polars:>14.2f}\")\n",
    "print(f\"{'TIME-optimized':<20} {'Pandas':<10} {delta_pandas:>14.2f}\")\n",
    "print(f\"{'MEMORY-optimized':<20} {'Polars':<10} {delta_polars_memory:>14.2f}\")\n",
    "print(f\"{'MEMORY-optimized':<20} {'Pandas':<10} {delta_pandas_memory:>14.2f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nMEMORY EFFICIENCY:\")\n",
    "print(\"-\" * 80)\n",
    "time_mem_ratio = delta_pandas / delta_polars if delta_polars > 0 else float('inf')\n",
    "memory_mem_ratio = delta_pandas_memory / delta_polars_memory if delta_polars_memory > 0 else float('inf')\n",
    "print(f\"TIME approach:   Polars is {time_mem_ratio:.2f}x more memory efficient than Pandas\")\n",
    "print(f\"MEMORY approach: \", end=\"\")\n",
    "if delta_polars_memory < delta_pandas_memory:\n",
    "    print(f\"Polars is {memory_mem_ratio:.2f}x more memory efficient than Pandas\")\n",
    "else:\n",
    "    print(f\"Pandas is {1/memory_mem_ratio:.2f}x more memory efficient than Polars\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-summary-analysis",
   "metadata": {},
   "source": [
    "TODO: An√°lisis consolidado de trade-offs\n",
    "- Comparar Q2 vs Q1 en t√©rminos de speedups y memory efficiency\n",
    "- Evaluar si el procesamiento de emojis cambia las conclusiones generales\n",
    "- Identificar el enfoque recomendado para Q2 en producci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones Globales Q2 ‚Äì Comparaci√≥n TIME vs MEMORY (Polars vs Pandas)\n",
    "\n",
    "TODO: Escribir conclusiones finales basadas en los resultados experimentales\n",
    "\n",
    "Aspectos a cubrir:\n",
    "\n",
    "### 1. Tiempo de Ejecuci√≥n\n",
    "TODO: Analizar tabla de tiempos consolidada\n",
    "- Comparar speedups TIME vs MEMORY\n",
    "- Evaluar consistencia vs Q1\n",
    "- Identificar bottlenecks espec√≠ficos de extracci√≥n de emojis\n",
    "\n",
    "### 2. Uso de Memoria (Delta RSS)\n",
    "TODO: Analizar tabla de memoria consolidada\n",
    "- Comparar deltas TIME vs MEMORY\n",
    "- Evaluar overhead del Counter\n",
    "- Comparar con Q1 para identificar diferencias\n",
    "\n",
    "### 3. Escalabilidad Esperada\n",
    "TODO: Proyectar comportamiento con datasets m√°s grandes\n",
    "- Evaluar c√≥mo escala emoji.emoji_list() con m√°s tweets\n",
    "- Predecir impacto en memoria y tiempo\n",
    "- Comparar con Q1\n",
    "\n",
    "### 4. Trade-offs Arquitecturales\n",
    "TODO: Evaluar cu√°ndo usar cada enfoque\n",
    "- Polars TIME vs Polars MEMORY\n",
    "- Pandas TIME vs Pandas MEMORY\n",
    "- Comparaci√≥n cruzada\n",
    "\n",
    "### 5. Recomendaci√≥n Final\n",
    "TODO: Recomendar enfoque √≥ptimo para Q2\n",
    "- Considerar tiempo, memoria y escalabilidad\n",
    "- Comparar con recomendaci√≥n de Q1\n",
    "- Justificar decisi√≥n con datos experimentales\n",
    "\n",
    "### 6. Limitaciones y Trabajos Futuros\n",
    "TODO: Identificar limitaciones del an√°lisis actual\n",
    "- Limitaciones de emoji.emoji_list() (row-by-row processing)\n",
    "- Posibles optimizaciones (UDFs, paralelizaci√≥n)\n",
    "- Alternativas a la librer√≠a emoji\n",
    "- Impacto de emojis compuestos\n",
    "\n",
    "### Conclusi√≥n Final\n",
    "\n",
    "TODO: Resumir hallazgos principales y recomendaci√≥n definitiva para Q2 en producci√≥n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
