# Q2: Top 10 emojis m√°s usados

## Objetivo
Obtener los top 10 emojis m√°s usados en tweets. Retornar el emoji y su conteo de ocurrencias.

## Enfoque

### Optimizaci√≥n por tiempo (q2_time.py)

**Estrategia**: Carga completa en memoria usando Polars con procesamiento vectorizado.

**Caracter√≠sticas**:
- Carga completa del dataset en memoria (scan_ndjson + collect)
- Extracci√≥n vectorizada de emojis usando map_elements
- Operaciones de explode + group_by para conteo eficiente
- Garbage collection estrat√©gico para liberar memoria intermedia
- Trade-off: velocidad m√°xima a costa de mayor uso de RAM

**Complejidad**:
- Tiempo: O(n) para procesamiento + O(k log k) para sort (k = emojis √∫nicos)
- Espacio: O(n) por DataFrame en memoria + O(m) por lista de emojis (m = total emojis)

#### Ejecuci√≥n

**Prerequisitos**:
Asegurarse que el dataset existe en `data/raw/farmers-protest-tweets-2021-2-4.json`. Si no existe, descargar primero:
```bash
python src/dataset/download_dataset.py
```

**Comando de ejecuci√≥n**:
```bash
python src/q2/q2_time_impl.py
```

**Salida esperada**:
- Muestra los top 10 emojis m√°s usados con su conteo
- Ejecuta profiling de tiempo con cProfile
- Ejecuta profiling de memoria con memray (si est√° instalado)

**Archivos generados**:
- `q2_time_polars.prof` - Profiling de tiempo (cProfile)
- `q2_time_polars_mem.bin` - Profiling de memoria (memray)

#### An√°lisis de profiling

**Analizar profiling de tiempo**:
```bash
python -m pstats q2_time_polars.prof
```

Comandos √∫tiles dentro de pstats:
```
stats 10        # Top 10 funciones por tiempo total
sort cumulative # Ordenar por tiempo acumulativo
sort time       # Ordenar por tiempo propio
```

**Analizar profiling de memoria**:
```bash
# Ver estad√≠sticas generales
memray stats q2_time_polars_mem.bin
```

**Nota**: Si memray no est√° instalado, se puede instalar con:
```bash
pip install memray
```

### Optimizaci√≥n por memoria (q2_memory.py)

**Estrategia**: Procesamiento por chunks con materializaci√≥n m√≠nima.

**Caracter√≠sticas**:
- Procesamiento en chunks para minimizar carga en memoria
- Conteo incremental usando Counter
- Solo materializa resultados peque√±os (top 10 emojis)
- Trade-off: menor consumo de memoria a costa de mayor tiempo de ejecuci√≥n

**Complejidad**:
- Tiempo: O(n) para procesamiento secuencial por chunks
- Espacio: O(1) - solo almacena chunk actual + Counter de emojis √∫nicos

#### Ejecuci√≥n

**Prerequisitos**:
Asegurarse que el dataset existe en `data/raw/farmers-protest-tweets-2021-2-4.json`. Si no existe, descargar primero:
```bash
python src/dataset/download_dataset.py
```

**Comando de ejecuci√≥n**:
```bash
python src/q2/q2_memory_impl.py
```

**Salida esperada**:
- Muestra los top 10 emojis m√°s usados con su conteo
- Ejecuta profiling de tiempo con cProfile
- Ejecuta profiling de memoria con memray (si est√° instalado)

**Archivos generados**:
- `q2_memory_polars.prof` - Profiling de tiempo (cProfile)
- `q2_memory_polars_mem.bin` - Profiling de memoria (memray)

#### An√°lisis de profiling

**Analizar profiling de tiempo**:
```bash
python -m pstats q2_memory_polars.prof
```

Comandos √∫tiles dentro de pstats:
```
stats 10        # Top 10 funciones por tiempo total
sort cumulative # Ordenar por tiempo acumulativo
sort time       # Ordenar por tiempo propio
```

**Analizar profiling de memoria**:
```bash
# Ver estad√≠sticas generales
memray stats q2_memory_polars_mem.bin
```

**Nota**: Si memray no est√° instalado, se puede instalar con:
```bash
pip install memray
```

---

## Resumen de Resultados y Conclusiones (TIME vs MEMORY) ‚Äì Q2

Para **Q2 (Top 10 emojis m√°s usados)** se implementaron y perfilaron dos enfoques con **Polars**, optimizados respectivamente por **tiempo** y por **memoria**. Ambos enfoques producen **resultados id√©nticos y deterministas**, por lo que la comparaci√≥n se centra exclusivamente en **performance, perfil de ejecuci√≥n y consumo de memoria**.

---

## 1. Resultados Clave

| Enfoque | Tiempo ejecuci√≥n | Peak RSS | Caracter√≠stica dominante |
|--------|------------------|----------|--------------------------|
| **Polars TIME** | ~5.8 s (end-to-end) / ~15.1 s (cProfile) | ~411 MB | Materializaci√≥n temprana + vectorizaci√≥n |
| **Polars MEMORY** | ~5.8 s (end-to-end) / ~15.3 s (cProfile) | ~411 MB | Streaming lazy + menor materializaci√≥n |

**Observaciones clave**:
- Ambos enfoques retornan exactamente el mismo top 10 de emojis con los mismos conteos.
- El tiempo end-to-end es pr√°cticamente id√©ntico en TIME y MEMORY.
- El consumo m√°ximo de memoria (Peak RSS) es muy similar en ambos casos.

---

## 2. Insights de Performance

### Polars TIME
- El tiempo est√° dominado por:
  - extracci√≥n de emojis (`emoji_list`, `tokenize`),
  - ejecuci√≥n de `map_elements()` sobre la columna `content`.
- El **parsing de emojis es el verdadero bottleneck**, no Polars.
- `LazyFrame.collect()` ejecuta una sola vez, pero el costo de CPU est√° en Python (emoji parsing).
- Ideal cuando:
  - el dataset cabe en memoria,
  - se busca el menor overhead conceptual y de implementaci√≥n.

### Polars MEMORY
- A diferencia de Q1, **no hay m√∫ltiples scans completos del dataset**.
- La mayor parte del tiempo se consume igualmente en:
  - `emoji.tokenizer.tokenize`,
  - `emoji.core.emoji_list`.
- `collect()` tiene un costo marginal (~0.1 s).
- El enfoque MEMORY **no penaliza significativamente el tiempo** para este problema.

**Conclusi√≥n clave**:
> En Q2, el costo computacional est√° dominado por el **procesamiento de texto y emojis**, no por el modelo de ejecuci√≥n (TIME vs MEMORY).

---

## 3. Insights de Memoria (memray)

### Observaciones comunes
- Ambos enfoques presentan un patr√≥n de memoria **estable y controlado**.
- Las mayores asignaciones corresponden a:
  - buffers Arrow (~407 MB),
  - resultados intermedios de `map_elements()` (~50‚Äì55 MB).
- No se observan fugas de memoria ni crecimiento incremental.

### Comparaci√≥n TIME vs MEMORY
- **Peak RSS pr√°cticamente id√©ntico (~411 MB)**.
- La diferencia entre TIME y MEMORY es m√≠nima porque:
  - el dataset no genera presi√≥n real de memoria,
  - Arrow utiliza buffers grandes y eficientes en ambos enfoques,
  - la extracci√≥n de emojis domina tanto CPU como memoria.

Esto confirma que, para este tama√±o de datos, **MEMORY no reduce significativamente el pico de memoria**, pero tampoco lo empeora.

---

## 4. Implicaciones de Escalabilidad

- A medida que el dataset crezca:
  - la memoria seguir√° escalando de forma eficiente en ambos enfoques (Arrow),
  - el tiempo crecer√° principalmente por el costo de parsing de emojis.
- El enfoque MEMORY:
  - evita depender de una materializaci√≥n temprana,
  - mantiene la misma sem√°ntica y stack,
  - ser√° m√°s robusto cuando el dataset no quepa en RAM.

Por esta raz√≥n, **Polars sigue siendo la opci√≥n recomendada en todos los escenarios**, eligiendo TIME o MEMORY seg√∫n disponibilidad de memoria, no por performance en Q2.

---

## 5. Decisi√≥n Final para Q2

- **Recomendaci√≥n principal**:  
  üëâ `q2_time.py` (**Polars TIME**)  
  C√≥digo m√°s simple, mismo rendimiento efectivo y sin trade-offs negativos para este dataset.

- **Alternativa cuando la RAM sea el factor limitante**:  
  üëâ `q2_memory.py` (**Polars MEMORY**)  
  Mismo resultado, mismo costo computacional dominante, mayor robustez ante datasets m√°s grandes.

---

## Conclusi√≥n General

- En Q2, **TIME y MEMORY convergen en performance real**.
- El factor dominante es el **procesamiento de emojis en Python**, no el motor de ejecuci√≥n de Polars.
- El uso de Polars garantiza:
  - ejecuci√≥n estable,
  - uso eficiente de memoria,
  - escalabilidad futura sin cambios de stack.

En resumen:

> **Usar siempre Polars**.  
> TIME si el dataset cabe c√≥modamente en RAM.  
> MEMORY si se anticipa crecimiento del dataset o restricciones de memoria.

Este an√°lisis confirma que las decisiones est√°n respaldadas por **profiling real de CPU y memoria**, y que el cuello de botella de Q2 es sem√°ntico (emoji parsing), no arquitectural.

