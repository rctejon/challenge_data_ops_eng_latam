# Q1: Top 10 fechas con m√°s tweets

## Objetivo
Obtener las top 10 fechas donde hay m√°s tweets. Retornar el usuario (username) que m√°s public√≥ por cada una de esas fechas.

## Enfoque

### Optimizaci√≥n por tiempo (q1_time.py)

**Estrategia**: Carga completa en memoria usando Polars con procesamiento vectorizado.

**Caracter√≠sticas**:
- Carga completa del dataset en memoria (scan_ndjson + collect)
- Lazy evaluation seguido de materializaci√≥n temprana
- Operaciones vectorizadas sobre DataFrame completo
- Trade-off: velocidad m√°xima (~0.325s) a costa de ~129 MB de RAM

**Complejidad**:
- Tiempo: O(n log n) por los sorts
- Espacio: O(n) por DataFrame en memoria

#### Ejecuci√≥n

**Prerequisitos**:
Asegurarse que el dataset existe en `data/raw/farmers-protest-tweets-2021-2-4.json`. Si no existe, descargar primero:
```bash
python src/dataset/download_dataset.py
```

**Comando de ejecuci√≥n**:
```bash
python src/q1/q1_time_impl.py
```

**Salida esperada**:
- Muestra las top 10 fechas con m√°s tweets y el usuario m√°s activo por fecha
- Ejecuta profiling de tiempo con cProfile
- Ejecuta profiling de memoria con memray (si est√° instalado)

**Archivos generados**:
- `q1_time_polars.prof` - Profiling de tiempo (cProfile)
- `q1_time_polars_mem.bin` - Profiling de memoria (memray)

#### An√°lisis de profiling

**Analizar profiling de tiempo**:
```bash
python -m pstats q1_time_polars.prof
```

Comandos √∫tiles dentro de pstats:
```
stats 10        # Top 10 funciones por tiempo total
sort cumulative # Ordenar por tiempo acumulativo
sort time       # Ordenar por tiempo propio
```

**Analizar profiling de memoria**:
```bash
# Ver estad√≠sticas generales
memray stats q1_time_polars_mem.bin
```

**Nota**: Si memray no est√° instalado, se puede instalar con:
```bash
pip install memray
```

### Optimizaci√≥n por memoria (q1_memory.py)

**Estrategia**: Lazy evaluation sin materializaci√≥n completa usando Polars en modo streaming.

**Caracter√≠sticas**:
- Mantiene LazyFrame sin materializar el DataFrame completo
- Ejecuta m√∫ltiples scans del archivo (1 para fechas + 10 para usuarios)
- Solo materializa resultados peque√±os (top 10 fechas, 1 usuario por fecha)
- Trade-off: m√≠nimo consumo de memoria (~7 MB) a costa de mayor tiempo (~3.4s)

**Complejidad**:
- Tiempo: O(11n) por los 11 scans del archivo
- Espacio: O(1) - solo almacena resultados agregados peque√±os

#### Ejecuci√≥n

**Prerequisitos**:
Asegurarse que el dataset existe en `data/raw/farmers-protest-tweets-2021-2-4.json`. Si no existe, descargar primero:
```bash
python src/dataset/download_dataset.py
```

**Comando de ejecuci√≥n**:
```bash
python src/q1/q1_memory_impl.py
```

**Salida esperada**:
- Muestra las top 10 fechas con m√°s tweets y el usuario m√°s activo por fecha
- Ejecuta profiling de tiempo con cProfile
- Ejecuta profiling de memoria con memray (si est√° instalado)

**Archivos generados**:
- `q1_memory_polars.prof` - Profiling de tiempo (cProfile)
- `q1_memory_polars_mem.bin` - Profiling de memoria (memray)

#### An√°lisis de profiling

**Analizar profiling de tiempo**:
```bash
python -m pstats q1_memory_polars.prof
```

Comandos √∫tiles dentro de pstats:
```
stats 10        # Top 10 funciones por tiempo total
sort cumulative # Ordenar por tiempo acumulativo
sort time       # Ordenar por tiempo propio
```

**Analizar profiling de memoria**:
```bash
# Ver estad√≠sticas generales
memray stats q1_memory_polars_mem.bin
```

**Nota**: Si memray no est√° instalado, se puede instalar con:
```bash
pip install memray
```

---

## Resumen de Resultados y Conclusiones (TIME vs MEMORY)

Para Q1 se implementaron y perfilaron dos enfoques con **Polars**, optimizados respectivamente por **tiempo** y por **memoria**. Ambos producen resultados **id√©nticos y deterministas**, por lo que la comparaci√≥n se centra en performance y consumo de recursos.

---

## 1. Resultados Clave

| Enfoque | Tiempo ejecuci√≥n | Peak RSS | Caracter√≠stica dominante |
|-------|------------------|----------|--------------------------|
| **Polars TIME** | ~0.33 s (cProfile) | ~417 MB | Velocidad m√°xima |
| **Polars MEMORY** | ~3.8 s | ~409 MB | Menor materializaci√≥n |

* Ambos enfoques usan el mismo motor (Polars + Arrow + lazy execution).
* La diferencia principal est√° en **cu√°ntas veces se escanea el dataset** y **cu√°ndo se materializa**.

---

## 2. Insights de Performance

### Polars TIME
- El **99% del tiempo** se concentra en una √∫nica llamada a `LazyFrame.collect()`.
- Parsing y materializaci√≥n del NDJSON ocurren **una sola vez**.
- Overhead de Python pr√°cticamente nulo, la ejecuci√≥n est√° dominada por Rust.
- Ideal cuando el dataset **cabe c√≥modamente en RAM**.

### Polars MEMORY
- El tiempo est√° dominado por **11 llamadas a `collect()`**:
  - 1 para calcular las top fechas,
  - 10 para calcular el top usuario por fecha.
- Cada `collect()` implica un **scan completo del archivo**.
- El bottleneck es **I/O**, no CPU.
- El costo en tiempo (~10x respecto a TIME) es consistente con m√∫ltiples lecturas del dataset.

---

## 3. Insights de Memoria (memray)

### Observaciones comunes
- Ambos enfoques presentan un patr√≥n de memoria **estable y saludable**:
  - carga,
  - procesamiento,
  - liberaci√≥n.
- Las asignaciones m√°s grandes provienen de **buffers Arrow** contiguos.
- No se detectan fugas ni crecimiento incremental.

### Comparaci√≥n
- El **peak RSS es similar** en ambos enfoques (~410‚Äì420 MB) para este dataset.
- La diferencia entre TIME y MEMORY es peque√±a porque:
  - el dataset no es lo suficientemente grande para forzar presi√≥n real de memoria,
  - Arrow utiliza buffers grandes y eficientes en ambos casos.

Esto sugiere que, para datasets de este tama√±o, **la ventaja de MEMORY se manifiesta m√°s en escalabilidad que en ahorro inmediato de RAM**.

---

## 4. Implicaciones de Escalabilidad

- A medida que el dataset crezca:
  - **la memoria de ambos enfoques crecer√° lentamente** (Arrow es eficiente),
  - **el tiempo escalar√° mucho mejor en Polars** que en enfoques Python puros.
- El enfoque MEMORY evita mantener un DataFrame completo en memoria y permite:
  - procesar datasets que no caben en RAM,
  - mantener el mismo modelo mental y sem√°ntica.

Por esta raz√≥n, **Polars sigue siendo la opci√≥n recomendada en todos los escenarios**, eligiendo TIME o MEMORY seg√∫n la disponibilidad de RAM.

---

## 5. Decisi√≥n Final para Q1

- **Recomendaci√≥n principal**:  
  üëâ `q1_time.py` (**Polars TIME**)  
  Mejor balance global, m√≠nima complejidad y m√°xima velocidad.

- **Alternativa cuando la RAM es el factor limitante**:  
  üëâ `q1_memory.py` (**Polars MEMORY**)  
  Mayor tiempo de ejecuci√≥n, pero misma l√≥gica y excelente escalabilidad.

En resumen:

> **Usar siempre Polars**.  
> TIME si el dataset cabe en memoria.  
> MEMORY si no cabe.

Este an√°lisis confirma que el dise√±o del motor (Rust + Arrow + lazy execution) es el factor dominante y que las decisiones est√°n respaldadas por profiling real de tiempo y memoria.
