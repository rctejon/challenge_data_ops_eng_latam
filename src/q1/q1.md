# Q1: Top 10 fechas con más tweets

## Objetivo
Obtener las top 10 fechas donde hay más tweets. Retornar el usuario (username) que más publicó por cada una de esas fechas.

## Enfoque

### Optimización por tiempo (q1_time.py)

**Estrategia**: Carga completa en memoria usando Polars con procesamiento vectorizado.

**Características**:
- Carga completa del dataset en memoria (scan_ndjson + collect)
- Lazy evaluation seguido de materialización temprana
- Operaciones vectorizadas sobre DataFrame completo
- Trade-off: velocidad máxima (~0.325s) a costa de ~129 MB de RAM

**Complejidad**:
- Tiempo: O(n log n) por los sorts
- Espacio: O(n) por DataFrame en memoria

#### Ejecución

**Prerequisitos**:
Asegurarse que el dataset existe en `data/raw/farmers-protest-tweets-2021-2-4.json`. Si no existe, descargar primero:
```bash
python src/dataset/download_dataset.py
```

**Comando de ejecución**:
```bash
python src/q1/q1_time_impl.py
```

**Salida esperada**:
- Muestra las top 10 fechas con más tweets y el usuario más activo por fecha
- Ejecuta profiling de tiempo con cProfile
- Ejecuta profiling de memoria con memray (si está instalado)

**Archivos generados**:
- `q1_time_polars.prof` - Profiling de tiempo (cProfile)
- `q1_time_polars_mem.bin` - Profiling de memoria (memray)

#### Análisis de profiling

**Analizar profiling de tiempo**:
```bash
python -m pstats q1_time_polars.prof
```

Comandos útiles dentro de pstats:
```
stats 10        # Top 10 funciones por tiempo total
sort cumulative # Ordenar por tiempo acumulativo
sort time       # Ordenar por tiempo propio
```

**Analizar profiling de memoria**:
```bash
# Ver estadísticas generales
memray stats q1_time_polars_mem.bin
```

**Nota**: Si memray no está instalado, se puede instalar con:
```bash
pip install memray
```

---

## Resumen de Resultados y Conclusiones

La implementación **TIME-optimized con Polars** cumple plenamente el objetivo de Q1 y valida las decisiones técnicas tomadas durante el análisis previo.

### Resultados clave

- **Tiempo de ejecución real**: ~0.33 s (cProfile)
- **Tiempo end-to-end del script**: ~0.5 s (incluyendo arranque y profiling)
- **Uso máximo de memoria (Peak RSS)**: ~417 MB
- **Correctitud**: resultados consistentes y deterministas en todas las ejecuciones

### Insights de performance

- El **99% del tiempo de ejecución** se concentra en `LazyFrame.collect()`, lo que indica que el costo dominante es:
  - parsing del NDJSON,
  - materialización del DataFrame Arrow en memoria.
- El overhead de Python es **prácticamente inexistente**; la ejecución está dominada por código nativo en Rust.
- Operaciones como `group_by`, `sort` y `filter` tienen un costo marginal comparado con la materialización.

### Insights de memoria

- El patrón de memoria es **predecible y saludable**:
  - carga del dataset,
  - procesamiento,
  - liberación al finalizar.
- Las mayores asignaciones provienen de buffers Arrow (bloques grandes y contiguos), lo cual favorece:
  - eficiencia de cache,
  - baja fragmentación,
  - alto rendimiento analítico.
- No se detectan fugas de memoria ni crecimiento incremental anómalo.

### Implicaciones técnicas

- Para datasets de este tamaño (~389 MB), **Polars TIME ofrece el mejor balance posible** entre velocidad y consumo de memoria.
- A medida que el dataset crezca, el uso de memoria escalará de forma aproximadamente lineal, mientras que el tiempo seguirá beneficiándose del motor vectorizado y paralelo de Polars.
- En escenarios donde el dataset **no quepa completamente en RAM**, la alternativa natural es **Polars MEMORY**, manteniendo el mismo stack y semántica.

### Decisión final para Q1

- **Recomendación principal**: usar `q1_time.py` (Polars TIME) como solución de referencia.
- **Alternativa**: usar la versión MEMORY solo cuando la RAM disponible sea el factor limitante.

Este profiling confirma que la solución es **production-ready**, con comportamiento estable, eficiente y alineado con buenas prácticas de ingeniería de datos.
